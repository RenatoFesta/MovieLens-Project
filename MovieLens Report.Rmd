---
title: "Movie Lens Project"
author: "Renato Festa"
date: "2023-03-01"
output: word_document
---

# Overview

The Movie Lens Project is a part of the HarvardX Data Science Certificate Program. The goal is to build a recommendation system using the knowledge acquired from the course. We will use the MovieLens dataset provided by the course to run this project, which contains 10 million ratings from different users for different movies. The code to obtain the data has already been split into edx (train set) and final_holdout_test (test set).

# Method

To calculate the accuracy of the prediction, we will compute the **RMSE** of the final code. RMSE stands for Root Mean Square Error, and it is one of the most commonly used methods for calculating differences between values. When computing the RMSE, we should aim to obtain a lower value. This means that at each step of the code, we will try to improve the results with the goal of achieving a lower RMSE.

        RMSE = √((1/N) *∑u,i(y^u,i−yu,i)2

# Analyzing and understanding the MovieLens dataset

```{R echo= FALSE, message=FALSE, warning=FALSE}
##########################################################
# Create edx and final_holdout_test sets 
##########################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")

library(stringr)
library(caret)
library(tidyr)
library(dslabs)
library(dplyr)
library(readr)
library(ggplot2)

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

options(timeout = 120)

dl <- "ml-10M100K.zip"
if(!file.exists(dl))
  download.file("https://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings_file <- "ml-10M100K/ratings.dat"
if(!file.exists(ratings_file))
  unzip(dl, ratings_file)

movies_file <- "ml-10M100K/movies.dat"
if(!file.exists(movies_file))
  unzip(dl, movies_file)

ratings <- as.data.frame(str_split(read_lines(ratings_file), fixed("::"), simplify = TRUE),
                         stringsAsFactors = FALSE)
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
ratings <- ratings %>%
  mutate(userId = as.integer(userId),
         movieId = as.integer(movieId),
         rating = as.numeric(rating),
         timestamp = as.integer(timestamp))

movies <- as.data.frame(str_split(read_lines(movies_file), fixed("::"), simplify = TRUE),
                        stringsAsFactors = FALSE)
colnames(movies) <- c("movieId", "title", "genres")
movies <- movies %>%
  mutate(movieId = as.integer(movieId))

movielens <- left_join(ratings, movies, by = "movieId")

# Final hold-out test set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.6 or later
set.seed(1) # if using R 3.5 or earlier

test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in final hold-out test set are also in edx set

final_holdout_test <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from final hold-out test set back into edx set

removed <- anti_join(temp, final_holdout_test)
edx <- rbind(edx, removed)
```

In order to make a more accurate prediction, all of the analysis will be performed only on the training set, which is the edx dataset. First, let's understand the size of this dataset:

```{R, echo = FALSE}
     length(edx$rating)
     
```

It is a large dataset, and as a result, some methods of analysis may not be feasible due to the computational effort required to compute predictions.

Now, let's understand how many columns there are in the dataset and what class of information is contained in each column.

```{R, echo = FALSE}
str(edx)
```

Here, we can see that the dataset is a data.frame with 6 columns, which contain information about a specific rating, such as who rated which movie, the genre of the movie, and the rating that the user gave.

For a better visualization, let's take a look at the head of the dataset:

```{R, echo = FALSE}
head(edx)
```

So, the edx dataset has more than 9 million rows. But, how many movies were rated, and how many users rated those movies?

```{R, echo = FALSE}
edx %>% summarize(Users = n_distinct(userId), movies = n_distinct(movieId))

```

**Movies specifics**

Lets see which movie has the greatest rating score

```{R, echo = FALSE}
x <- edx %>% group_by(movieId) %>% mutate(mean_rating = mean(rating))
y <- edx$movieId[which.max(x$mean_rating)]
edx %>% filter(movieId == y)
```

This is the movie with the highest rating from this list. However, it had only 1 rating from users. How often do movies get to the top of the ranking because they have few ratings?

```{R, echo = FALSE}
edx %>% group_by(title) %>% summarize(rates = n(), mean_rating = mean(rating)) %>% filter(rates <= 100) %>% arrange(desc(mean_rating)) %>% head()
```

Here, we can observe that the movies with the highest ratings are the ones with less than 2 ratings. To get a more accurate understanding, we should remove the movies with few ratings. Let's only calculate the ratings for the movies with 100 or more ratings and see which one has the highest rating.

```{R, echo = FALSE}
edx %>% group_by(title) %>%
  summarize(rates = n(), mean_rating = mean(rating)) %>%
  filter(rates >= 100) %>%
  arrange(desc(mean_rating)) %>%
  head()
```

Now it makes more sense. The best-rated movie is The Shawshank Redemption, which has 28,015 ratings. Looking at this list, we can also notice that the six highest-rated movies were all released before the year 2000. We will investigate this further later.

Despite having the highest mean rating, does The Shawshank Redemption have the most ratings overall?

```{R, echo = FALSE}
edx %>% group_by(title) %>%
  summarize(rates = n(), mean_rating = mean(rating)) %>%
  filter(rates >= 100) %>%
  arrange(desc(rates)) %>%
  head()
```

Pulp Fiction is the movie with the most ratings. However, it was not enough to put it in the top 6 movies. Now, let's take a look at the worst-rated movies on the list.

```{R, echo = FALSE}
edx %>% group_by(title) %>%
  summarize(rates = n(), mean_rating = mean(rating)) %>%
  filter(rates >= 100) %>%
  arrange(mean_rating) %>%
  head()
```

The worst-rated movies also have very few ratings. This highlights the importance of recommendations in guiding users towards better content.

**Genres specifics**

Another aspect of the movies is their genres. Certain genres may have more views and better acceptance than others.

```{R, echo = FALSE}
edx %>%
  separate_rows(genres, sep = "\\|") %>%
  group_by(genres) %>%
  summarize(count = n()) %>%
  arrange(-count) %>%
  ggplot(aes(count, reorder(genres, count))) +
  geom_col() + 
  xlab("Count") +
  ylab(NULL)
```

Drama and Comedy are the most rated movies on our list. Now lets see if they are the ones with best ratings:

```{R, echo = FALSE}
edx %>%
  separate_rows(genres, sep = "\\|") %>%
  group_by(genres) %>%
  summarize(mean_rating = mean(rating)) %>%
  arrange(-mean_rating) %>%
  ggplot(aes(mean_rating, reorder(genres, mean_rating))) +
  geom_col() + 
  xlab("Rating") +
  ylab(NULL)

```

The highest-rated genres are Film-Noir and Documentary, but these movies also have a low number of ratings. Additionally, we can see that only one genre has an average rating higher than 4, and all genres have ratings higher than 3. To better understand the distribution of ratings throughout the dataset, let's plot the frequency of each rating.

```{R echo= FALSE, message=FALSE, warning=FALSE}
edx %>%
  ggplot(aes(rating, y = ..prop..)) +
  geom_bar() +
  scale_x_continuous(breaks = c(0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5)) +
  scale_y_continuous(labels = scales::percent)

```

More than half of the ratings fall between 3.0 and 4.0. We can also observe that most of the ratings were whole numbers, such as 3.0, 4.0, and 5.0.

**Year specifics**

In the next step, we will analyze the effect of time on movies. To do that, we need to create another column containing the release year of each movie.

```{R, echo = FALSE}
#creating a new column presenting the year_release
edx <- edx %>% mutate(year_release = as.numeric(str_sub(edx$title, start = -5, end = -2)))

edx %>% select( title, year_release) %>% head()

```

Now with the new column we can understand better the year effect:

```{R echo= FALSE, message=FALSE, warning=FALSE}
edx %>%
  group_by(year_release) %>%
  summarize(mean_rating = mean(rating)) %>%
  ggplot(aes(year_release, mean_rating)) +
  geom_smooth() +
  scale_x_continuous(breaks = seq(1915, 2008, 31))

```

```{R, echo = FALSE}
edx %>% 
  group_by(year_release) %>% 
  summarize(ratings = n()) %>%
  ggplot(aes(year_release, ratings)) +
  geom_line() +
  scale_x_continuous(breaks = seq(1908, 2008, 10))

```

The movies from the 90s and beyond have the highest number of ratings, but they also have the lowest average rating.

# Model of recommendation

Now we will build a recommendation model and work on it until we achieve the lowest RMSE value.

**Calculating the mean**

Let's calculate the RMSE using only the mean rating of the movies in the dataset. As we learned during the analysis, to make better predictions, let's filter the dataset to only include movies with 100 or more ratings to achieve a better RMSE value.

```{R, echo = FALSE}
#calculating the mean
meanRating <- edx %>% group_by(movieId) %>% filter(n() > 100) %>% ungroup()
meanRating <- mean(meanRating$rating)
print(c("Mean rating:", meanRating))

#calculating the RMSE
AverageRatingRMSE <- RMSE(final_holdout_test$rating, meanRating)
print(c("RMSE:",AverageRatingRMSE))
```

The average rating for movies with more than 100 ratings is 3.52. If we use only this value to recommend movies, the resulting RMSE will be 1.061232.

**Using the user effect**

As some users are more optimistic than others, we will use this information to personalize the recommendations for each of them. We will assign higher ratings to users who typically give higher ratings and lower ratings to the more pessimistic ones

```{R, echo = FALSE}
userMean <- edx %>% group_by(userId) %>% summarize(estDeviUser = mean(rating - meanRating))

predUserRating <- final_holdout_test %>%
  left_join(userMean, by = 'userId') %>%
  mutate(recommendation = estDeviUser + meanRating) %>%
  select(userId, recommendation)


RMSEpredUserRating <- RMSE(final_holdout_test$rating, predUserRating$recommendation)
print(c("RMSE:", RMSEpredUserRating))
```

With this, we can improve our results, which means we are getting better predictions of the ratings that users would give to certain movies.

**Using the movie effect**

We can observe from the plots that some movies have higher ratings than others. By implementing a ranking system to compute predicted ratings, such that movies with better ratings receive higher predicted ratings, we should be able to achieve a lower RMSE. Let's utilize this information to calculate an even more accurate recommendation.

```{R, echo = FALSE}
movieMean <- edx %>% 
  left_join(userMean, by ='userId') %>%
  group_by(movieId) %>%
  summarize(estDeviMovie = mean(rating - meanRating - estDeviUser))

predMovieRating <- final_holdout_test %>%
  left_join(userMean, by='userId') %>%
  left_join(movieMean, by='movieId') %>%
  mutate( pred = meanRating + estDeviMovie + estDeviUser) %>%
  pull(pred)

predMovieRating <- RMSE(predMovieRating, final_holdout_test$rating)

print(c("RMSE:",predMovieRating))

```

## Results

Our final RMSE is 0.8822445. Despite trying different approaches, I couldn't lower it further. One of the reasons is that the dataset is quite large and requires significant computational effort.

```{R echo= FALSE, message=FALSE, warning=FALSE}
final_result <- data_frame(Approach = "Mean rating puls user and movie effect", RMSE = predMovieRating)
final_result %>% knitr::kable()
```

## Conclusion

Although this model is simple, it could still work as a recommendation system. It takes into account whether a user tends to rate movies more positively or negatively, as well as the overall rating of a movie among users. Therefore, if a user usually rates movies poorly, the recommendation system will predict a lower rating for them, and if a movie has a low rating among users, the system will predict an even lower rating. The opposite occurs for users who tend to be more optimistic in their ratings; they will receive recommendations with higher predicted ratings.

The major problem with this model is that it does not account for genre bias, which limits its predictive accuracy. If the dataset were smaller, I could use a K-nearest neighbor model to make better predictions. This would allow me to use all the collected data to calculate a predicted rating for the final holdout test.
